# FinLora-RAG-Real-time-Financial-Risk-Analysis-with-LoRA-tuned-Llama-3-SEC-RAG
æœ¬é¡¹ç›®é€šè¿‡LoRAå¾®è°ƒLlama-3-8Bä¸RAGå®æ—¶æ£€ç´¢SECæ–‡ä»¶ï¼ˆItem 1A/7ï¼‰ï¼Œæ„å»ºä¼ä¸šçº§é‡‘èåˆ†æAIã€‚é‡‡ç”¨BAAI/bge-large-enåµŒå…¥æ¨¡å‹ï¼Œç»ä¸¥æ ¼éªŒè¯ï¼ˆå›°æƒ‘åº¦â†“/ROUGEâ†‘/BLEUâ†‘/BERTScoreâ†‘ï¼‰ä¸ä¸‹æ¸¸è¯„ä¼°ï¼ˆäº‹å®å‡†ç¡®æ€§92.5%+ï¼‰ï¼Œæä¾›å¯æº¯æºçš„ç²¾å‡†å†³ç­–APIã€‚

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.10+](https://img.shields.io/badge/python-3.10%2B-blue.svg)](https://www.python.org/downloads/)

> **ç²¾å‡†åˆ†æ10-KæŠ¥å‘Šé£é™©å› ç´ (Item 1A)ä¸ç»è¥è®¨è®º(Item 7)**  
> åŸºäºLlama-3-8Bçš„LoRAå¾®è°ƒä¸å®æ—¶SECæ£€ç´¢å¢å¼ºæŠ€æœ¯ï¼Œæä¾›å¯æº¯æºçš„é‡‘èå†³ç­–æ”¯æŒ

## ğŸš€ æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. LoRAå¾®è°ƒè®­ç»ƒ (`lora_finetune_train.py`)
```python
# è‡ªå®šä¹‰è¯„ä¼°ç±»å®ç°
class ModelEvaluator:
    def calculate_perplexity(self, dataset):
        """è®¡ç®—éªŒè¯é›†å›°æƒ‘åº¦"""
        self.model.eval()
        with torch.no_grad():
            # æ‰¹é‡è®¡ç®—æŸå¤±
            total_loss = 0
            for batch in dataset:
                outputs = self.model(**batch, labels=batch.input_ids)
                total_loss += outputs.loss.item()
        return torch.exp(torch.tensor(total_loss / len(dataset)))

    def evaluate_generation_quality(self, dataset):
        """è¯„ä¼°ç”Ÿæˆè´¨é‡ï¼šROUGE/BLEU/BERTScore"""
        # éšæœºé‡‡æ ·ç”Ÿæˆé¢„æµ‹
        predictions, references = [], []
        for item in sampled_dataset:
            prompt = format_prompt(item["question"], item["context"])
            generated = generate_response(prompt)
            predictions.append(generated)
            references.append(item["answer"])
        
        # è®¡ç®—æŒ‡æ ‡
        rouge_scores = self.rouge_scorer.score(references, predictions)
        bleu_score = sacrebleu.corpus_bleu(predictions, [references]).score
        bert_precision, bert_recall, bert_f1 = self.bert_scorer.score(predictions, references)
        return {
            "rouge1": rouge_scores["rouge1"].fmeasure,
            "bert_f1": bert_f1.mean().item()
        }

# LoRAé…ç½®
model = FastLanguageModel.get_peft_model(
    model,
    r=64,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
    lora_alpha=128,
    lora_dropout=0.2
)
# è®­ç»ƒæµç¨‹
trainer = CustomSFTTrainer(
    model=model,
    train_dataset=financial_qa_dataset,
    eval_dataset=val_dataset,
    args=TrainingArguments(
        per_device_train_batch_size=2,
        learning_rate=1e-5,
        max_steps=60,
        eval_steps=10
    )
)
trainer.train()
```

### 2. RAGå¢å¼ºæ¨ç† (inference_RAG_main.py)
```python
# è®¾ç½®SEC 10-Kæ•°æ®ç®¡é“å’Œæ£€ç´¢åŠŸèƒ½
# æå–æ–‡ä»¶åŠŸèƒ½
def get_filings(ticker):
    global sec_api_key

    # ä½¿ç”¨QueryAPIæŸ¥æ‰¾æœ€è¿‘çš„æ–‡ä»¶
    queryApi = QueryApi(api_key=sec_api_key)
    query = {
      "query": f"ticker:{ticker} AND formType:\"10-K\"",
      "from": "0",
      "size": "1",
      "sort": [{ "filedAt": { "order": "desc" } }]
    }
    filings = queryApi.get_filings(query)

    # è·å–10-K URL
    filing_url = filings["filings"][0]["linkToFilingDetails"]

    # ä½¿ç”¨ExtractorAPIæå–æ–‡æœ¬
    extractorApi = ExtractorApi(api_key=sec_api_key)
    onea_text = extractorApi.get_section(filing_url, "1A", "text") # Section 1A - Risk Factors
    seven_text = extractorApi.get_section(filing_url, "7", "text") # Section 7 - Managementâ€™s Discussion and Analysis of Financial Condition and Results of Operations

    # èåˆæ–‡æœ¬
    combined_text = onea_text + "\n\n" + seven_text

    return combined_text


# HF Model è·¯å¾„
modelPath = "BAAI/bge-large-en-v1.5"
# åˆ›å»ºä¸€ä¸ªå¸¦æœ‰æ¨¡å‹é…ç½®é€‰é¡¹çš„å­—å…¸ï¼ŒæŒ‡å®šä½¿ç”¨cudaè¿›è¡ŒGPUä¼˜åŒ–
model_kwargs = {'device':'cuda'}
encode_kwargs = {'normalize_embeddings': True}

# ç”¨æŒ‡å®šçš„å‚æ•°åˆå§‹åŒ–ä¸€ä¸ªLangChainçš„HuggingFaceEmbeddingså®ä¾‹
embeddings = HuggingFaceEmbeddings(
    model_name=modelPath,     # æä¾›é¢„è®­ç»ƒæ¨¡å‹çš„è·¯å¾„
    model_kwargs=model_kwargs, # ä¼ é€’æ¨¡å‹é…ç½®é€‰é¡¹
    encode_kwargs=encode_kwargs # ä¼ é€’ç¼–ç é€‰é¡¹
)


"""
æ¥ä¸‹æ¥éœ€è¦å¤„ç†å’Œå®šä¹‰å‘é‡æ•°æ®åº“
åœ¨è¿™ä¸ªæµç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»ä¸Šè¿°å®šä¹‰çš„ SEC API å‡½æ•°è·å–æ•°æ®ï¼Œç„¶åç»å†ä¸‰ä¸ªæ­¥éª¤ï¼š1. æ–‡æœ¬åˆ†å‰²2. å‘é‡åŒ–3. æ£€ç´¢åŠŸèƒ½è®¾ç½®

æ–‡æœ¬åˆ†å‰²æ˜¯å°†å¤§å‹æ–‡æ¡£æˆ–æ–‡æœ¬æ•°æ®åˆ†è§£ä¸ºæ›´å°ã€æ›´æ˜“äºç®¡ç†çš„éƒ¨åˆ†çš„è¿‡ç¨‹ã€‚åœ¨å¤„ç†è¯¸å¦‚æ³•å¾‹æ–‡ä»¶ã€è´¢åŠ¡æŠ¥å‘Šæˆ–ä»»ä½•é•¿ç¯‡æ–‡ç« ç­‰å¤§é‡æ–‡æœ¬æ•°æ®æ—¶ï¼Œè¿™é€šå¸¸æ˜¯å¿…è¦çš„ã€‚æ–‡æœ¬åˆ†å‰²çš„ç›®çš„æ˜¯ç¡®ä¿æ•°æ®èƒ½å¤Ÿè¢«æœºå™¨å­¦ä¹ æ¨¡å‹å’Œæ•°æ®åº“æœ‰æ•ˆåœ°å¤„ç†ã€åˆ†æå’Œç´¢å¼•ã€‚

å‘é‡æ•°æ®åº“ä»¥å‘é‡çš„å½¢å¼å­˜å‚¨æ•°æ®ï¼Œå‘é‡æ˜¯æ–‡æœ¬ã€å›¾åƒæˆ–å…¶ä»–ç±»å‹æ•°æ®çš„æ•°å€¼è¡¨ç¤ºã€‚è¿™äº›å‘é‡èƒ½å¤Ÿæ•æ‰æ•°æ®çš„è¯­ä¹‰å«ä¹‰ï¼Œä»è€Œå®ç°é«˜æ•ˆçš„ç›¸ä¼¼æ€§æœç´¢å’Œæ£€ç´¢ã€‚

æˆ‘ä»¬è¿™é‡Œä½¿ç”¨çš„å‘é‡æ•°æ®åº“æ˜¯ [Facebook AI è¯­ä¹‰æœç´¢](https://ai.meta.com/tools/faiss/) åº“ï¼Œè¿™æ˜¯ä¸€ä¸ªè½»é‡çº§ä¸”å†…å­˜ä¸­çš„è§£å†³æ–¹æ¡ˆï¼ˆæ— éœ€å°†å…¶ä¿å­˜åˆ°ç£ç›˜ï¼‰ï¼Œè™½ç„¶ä¸åƒå…¶ä»–å‘é‡æ•°æ®åº“é‚£æ ·å¼ºå¤§ï¼Œä½†å¯¹äºæ­¤ç”¨ä¾‹æ¥è¯´æ•ˆæœå¾ˆå¥½ã€‚

å¦‚ä½•å°†æ‹†åˆ†æ–‡æ¡£å’ŒåµŒå…¥æŠ€æœ¯ç»“åˆä½¿ç”¨ï¼š
1. åµŒå…¥ï¼š å½“æ–‡æœ¬æ•°æ®è¢«åˆ†å‰²æˆè¾ƒå°çš„ç‰‡æ®µæ—¶ï¼Œæ¯ä¸ªç‰‡æ®µéƒ½ä¼šé€šè¿‡åµŒå…¥æ¨¡å‹è½¬æ¢ä¸ºæ•°å€¼å‘é‡ï¼ˆåµŒå…¥ï¼‰ã€‚è¿™äº›åµŒå…¥èƒ½å¤Ÿæ•æ‰æ–‡æœ¬çš„è¯­ä¹‰å…³ç³»å’Œå«ä¹‰ã€‚
2. å­˜å‚¨ï¼š å‘é‡æ•°æ®åº“ä¼šå°†è¿™äº›åµŒå…¥å‘é‡ä¸åŸå§‹æ–‡æœ¬å—çš„å¼•ç”¨ä¸€åŒå­˜å‚¨ã€‚
3. ç´¢å¼•ï¼š æ•°æ®åº“ä¼šå¯¹å‘é‡è¿›è¡Œç´¢å¼•ï¼Œä»¥ä¾¿å®ç°å¿«é€Ÿé«˜æ•ˆçš„ç›¸ä¼¼æ€§æœç´¢ã€‚è¿™ä¸€ç´¢å¼•è¿‡ç¨‹ä¼šå°†å‘é‡ä»¥ä¸€ç§æ˜“äºå¿«é€ŸæŸ¥æ‰¾ç›¸ä¼¼å‘é‡çš„æ–¹å¼è¿›è¡Œç»„ç»‡ã€‚
4. ç”¨æ³•ï¼š å½“è¿›è¡ŒæŸ¥è¯¢æ—¶ï¼Œå‘é‡æ•°æ®åº“ä¼šæœç´¢ä¸æŸ¥è¯¢å‘é‡æœ€ç›¸ä¼¼çš„å‘é‡ï¼ˆæ–‡æœ¬ç‰‡æ®µï¼‰ï¼Œæ ¹æ®å®ƒä»¬çš„è¯­ä¹‰ç›¸ä¼¼åº¦æ£€ç´¢å‡ºç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚
"""
# æç¤ºç”¨æˆ·è¾“å…¥ä»–ä»¬æƒ³è¦åˆ†æçš„è‚¡ç¥¨è¡Œæƒ…
ticker = input("What Ticker Would you Like to Analyze? ex. AAPL: ")

print("-----")
print("Getting Filing Data")
# æ£€ç´¢æŒ‡å®šä»£ç çš„å½’æ¡£æ•°æ®
filing_data = get_filings(ticker)

print("-----")
print("Initializing Vector Database")
# åˆå§‹åŒ–æ–‡æœ¬åˆ†å‰²å™¨ï¼Œå°†æ–‡ä»¶æ•°æ®åˆ†å‰²æˆchunks
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size = 1000,         # æ¯ä¸ªchunkçš„æœ€å¤§å¤§å°
    chunk_overlap = 500,       # chunksä¹‹é—´é‡å çš„å­—ç¬¦æ•°
    length_function = len,     # è¿™æ˜¯ç”¨æ¥ç¡®å®šchunksçš„é•¿åº¦
    is_separator_regex = False # åˆ†éš”ç¬¦æ˜¯å¦ä¸ºæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
)
# å°†å½’æ¡£æ•°æ®åˆ†æˆæ›´å°çš„ã€æ˜“äºç®¡ç†çš„æ•°æ®chunks
split_data = text_splitter.create_documents([filing_data])

# ä½¿ç”¨åµŒå…¥ä»åˆ†å‰²æ•°æ®åˆ›å»ºFAISSçŸ¢é‡æ•°æ®åº“
db = FAISS.from_documents(split_data, embeddings)

# åˆ›å»ºè¦åœ¨çŸ¢é‡æ•°æ®åº“ä¸­æœç´¢çš„æ£€ç´¢å¯¹è±¡
retriever = db.as_retriever()

print("-----")
print("Filing Initialized")


"""
Retrievalæ˜¯æŸ¥è¯¢çŸ¢é‡æ•°æ®åº“ä»¥æŸ¥æ‰¾å¹¶è¿”å›ä¸ç»™å®šæŸ¥è¯¢åŒ¹é…çš„ç›¸å…³æ–‡æœ¬å—æˆ–æ–‡æ¡£çš„è¿‡ç¨‹ã€‚è¿™æ¶‰åŠåˆ°æœç´¢ç´¢å¼•åµŒå…¥ï¼Œä»¥è¯†åˆ«ä¸æŸ¥è¯¢æœ€ç›¸ä¼¼çš„åµŒå…¥ã€‚
åœ¨è¿™ä¸ªå‡½æ•°ä¸­ï¼ŒæŸ¥è¯¢ç”¨äºè°ƒç”¨Retrievalï¼ŒRetrievalè¿”å›ä¸€ä¸ªæ–‡æ¡£åˆ—è¡¨ã€‚ç„¶åæå–è¿™äº›æ–‡æ¡£çš„å†…å®¹å¹¶ä½œä¸ºæŸ¥è¯¢çš„ä¸Šä¸‹æ–‡è¿”å›ã€‚
**å·¥ä½œåŸç†ï¼š**
1. **æŸ¥è¯¢åµŒå…¥ï¼š**å½“æŸ¥è¯¢ç”Ÿæˆæ—¶ï¼Œé¦–å…ˆä½¿ç”¨ä¸æ–‡æœ¬å—ç›¸åŒçš„åµŒå…¥æ¨¡å‹å°†å…¶è½¬æ¢ä¸ºåµŒå…¥ã€‚
2. **ç›¸ä¼¼æœç´¢ï¼š**æ£€ç´¢å™¨åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢ä¸æŸ¥è¯¢åµŒå…¥ç›¸ä¼¼çš„åµŒå…¥ã€‚è¿™ç§ç›¸ä¼¼æ€§é€šå¸¸ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æˆ–æ¬§å‡ é‡Œå¾—è·ç¦»ç­‰è·ç¦»åº¦é‡æ¥è¡¡é‡ã€‚
3. **æ–‡æ¡£æ£€ç´¢ï¼š**æ£€ç´¢å™¨ç„¶åæ£€ç´¢ä¸ç±»ä¼¼åµŒå…¥ç›¸å…³çš„åŸå§‹æ–‡æœ¬å—æˆ–æ–‡æ¡£ã€‚
4. **ä¸Šä¸‹æ–‡ç»„è£…ï¼š**æ£€ç´¢åˆ°çš„æ–‡æœ¬å—è¢«ç»„è£…ä»¥æä¾›ä¸€ä¸ªè¿è´¯çš„ä¸Šä¸‹æ–‡æˆ–æŸ¥è¯¢çš„ç­”æ¡ˆã€‚
"""
# Retrievalå‡½æ•°
def retrieve_context(query):
    global retriever
    retrieved_docs = retriever.invoke(query) # Invoke the retriever with the query to get relevant documents
    context = []
    for doc in retrieved_docs:
        context.append(doc.page_content) # Collect the content of each retrieved document
    return context
```

### ğŸ“‚ é¡¹ç›®ç»“æ„
```md
FinLora-RAG/
â”œâ”€â”€ lora_finetune_train.py       # æ¨¡å‹å¾®è°ƒè®­ç»ƒè„šæœ¬
â”œâ”€â”€ inference_RAG_main.py        # RAGæ¨ç†ä¸å¯¹è¯è„šæœ¬
â”œâ”€â”€ content/
â”‚   â””â”€â”€ drive/
â”‚       â””â”€â”€ LLaMa3-Financial-Analyst/
â”‚           â””â”€â”€ Fine-l3_finagent_step60_eval/  # é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ requirements.txt             # Pythonä¾èµ–
â””â”€â”€ README.md                    # é¡¹ç›®æ–‡æ¡£
```

### âš™ï¸ å¿«é€Ÿå¼€å§‹
1. ç¯å¢ƒå®‰è£…
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# æ ¸å¿ƒä¾èµ–ï¼š
# torch==2.3.0
# transformers==4.40.0
# unsloth==0.4.0
# sec-api==1.2.0
# faiss-cpu==1.8.0
# langchain==0.2.0
```

2. è®­ç»ƒé‡‘èé¢†åŸŸæ¨¡å‹
```bash
#è¯·åœ¨è®­ç»ƒå‰ï¼Œå°†loraçš„å‚æ•°ä»¥åŠè¯„ä¼°å‡½æ•°çš„å‚æ•°è®¾å®šæ”¹ä¸ºä½ æœ¬è½®å®éªŒçš„å€¼
python lora_finetune_train.py
```
è®­ç»ƒå¥½çš„æ¨¡å‹å°†ä¼šè‡ªåŠ¨ä¿å­˜è‡³/content/drive/LLaMa3-Financial-Analyst/Fine-l3_finagent_step60_evalæ–‡ä»¶å¤¹ä¸‹

3.å¯åŠ¨RAGå¯¹è¯ç³»ç»Ÿ
```bash
python inference_RAG_main.py

# äº¤äº’ç¤ºä¾‹:
What Ticker Would you Like to Analyze? ex. AAPL: AAPL
----- 
Getting Filing Data...
----- 
Initializing Vector Database...
-----
Filing Initialized

What would you like to know about AAPL's form 10-K? åˆ†æ2023å¹´ä¾›åº”é“¾é£é™©
```

4.ç¤ºä¾‹å›ç­”
```bash
LLaMa3 Agent: According to the data, the net sales in the Americas increased by 3% in 2024 compared to 2023, primarily due to higher net sales of Services.
What would you like to know about AAPL's form 10-K? 
```


## ç›¸å…³å·¥å…·æ”¯æŒ

- [swanlab](https://github.com/SwanHubX/SwanLab)ï¼šå¼€æºã€ç°ä»£åŒ–è®¾è®¡çš„æ·±åº¦å­¦ä¹ è®­ç»ƒè·Ÿè¸ªä¸å¯è§†åŒ–å·¥å…·
- [transformers](https://github.com/huggingface/transformers)ï¼šHuggingFaceæ¨å‡ºçš„åŒ…å«é¢„è®­ç»ƒæ–‡æœ¬ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘ã€è§†é¢‘å’Œå¤šæ¨¡æ€æ¨¡å‹çš„åº“ï¼Œç”¨äºæ¨ç†å’Œè®­ç»ƒ
- [peft](https://github.com/huggingface/peft)ï¼šç”¨äºé«˜æ•ˆå¾®è°ƒå¤§å‹è¯­è¨€æ¨¡å‹çš„åº“ã€
- [HuggingFace token](https://huggingface.co/settings/tokens)ï¼šç”¨äºå¯¼å…¥ç›¸å…³æ•°æ®é›†åŠæ¨¡å‹
- [Free SEC API Key](https://sec-api.io/)ï¼šå…è´¹è·å–SEC EDGARæ•°æ®çš„APIå¯†é’¥ 
- [meta-llama/Meta-Llama-3-8B-Instruct](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)ï¼šåŸºç¡€ä¸è®­ç»ƒæ¨¡å‹
- [Supervised Fine-Tuning Trainer](https://huggingface.co/docs/trl/sft_trainer)ï¼šTRLåº“çš„ç›‘ç£å¾®è°ƒè®­ç»ƒå™¨æ–‡æ¡£
- [Large English Embedding Model](https://huggingface.co/BAAI/bge-large-en-v1.5)ï¼šç”¨äºæ£€ç´¢çš„åµŒå…¥æ¨¡å‹
